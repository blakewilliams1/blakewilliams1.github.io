import{a as p}from"./chunk-GUB7ARD7.js";import"./chunk-U6DPD2OU.js";import{a as c}from"./chunk-IAM5JV3P.js";import{a as l,c as d,e as m,f as h}from"./chunk-US4Z7JDK.js";import"./chunk-ORYLB4O6.js";import{fb as e,ga as r,gb as t,hb as a,ub as i,xb as s}from"./chunk-NEKH66XV.js";var k=(()=>{class n{static{this.\u0275fac=function(o){return new(o||n)}}static{this.\u0275cmp=r({type:n,selectors:[["flip-dot-display-page"]],standalone:!0,features:[s],decls:33,vars:0,consts:[[1,"divider"],["videoId","s94PscZJ5EE"],["loading","lazy","imgurId","NaGwOYr"],["loading","lazy","imgurId","7IVaHO5"],["loading","lazy","imgurId","1mmVQLA"],["loading","lazy","imgurId","ITn7YlV"],["loop","","controls","","playsInline",""],["src","https://imgur.com/6z6NkLU.mp4","type","video/mp4"],["src","https://imgur.com/oezksWt.mp4","type","video/mp4"]],template:function(o,f){o&1&&(e(0,"mat-card")(1,"mat-card-header")(2,"h1"),i(3,"Flip Dot Display"),t()(),a(4,"div",0),e(5,"mat-card-content")(6,"p"),i(7," Before covid, there was a massive wall of flip dot displays tiled together in the lobby of one of the buildings at my work. It had a Microsoft Kinect sensor on it, and whenever you got close enough it would cast a silhouette of your body onto the wall that would mimic your motions. It was incredibly fun and made a really satisfying shimmering noise when in use, as the metallic disks flickered back and forth across the screens. Here's a video (not of the same wall) that gives an idea of what it was like: "),t(),a(8,"youtube-placeholder",1),e(9,"p"),i(10," When everyone eventually started returning back to office, the wall had fallen into disrepair. An important 3rd party service it used on boot-up had been killed off while everyone was working from home, and the original maintainers of the wall had since left the company as well. Some folks attempted to revive it, but after several weeks of fruitless effort it was deemed not worth the time investment anymore. The panels were taken down and posted as up for grabs on the internal Makers email list. Naturally I grabbed a few and attempted to make a mini version of the original wall for myself! "),t(),e(11,"p"),i(12," I felt the first step was to make a chassis to hold together the panels, so I bought some aluminum L-bracket from Home Depot and salvaged some aluminum T-slot rail from the recycle bins at work. Here's a progress shot of the backing frame coming together. The T-slot rails are being cut down to size and joined together "),t(),a(13,"img",2),e(14,"p"),i(15," I drilled and cut aluminum L bracket down to size to hold the panels onto a larger rigid frame that was made from the T-slot rails. "),t(),a(16,"img",3),e(17,"p"),i(18," Originally the display driver code was prototyped on an Arduino Uno. The mess of wires and a Raspberry Pi in the next photo was what I finally got working. I decided to go with a Raspberry Pi because there were convenient libraries for using cheap Intel RealSense depth cameras. The Raspberry Pi output is sent to a logic level shifter to convert from 3v to 5v, then finally that signal goes to a RS485 converter which the displays require. There is a lot small magnetic fields around the display to flip the discs, so they use RS485 twisted cabling to handle the large amount of electrical noise generated. "),t(),a(19,"img",4),e(20,"p"),i(21," I was having issues for the longest time getting the code to work on the Raspberry Pi even though it was working fine on the Arduino. This took an EMBARRASSINGLY long time to realize and I finally had to break out the oscilloscope and decode the data being sent from each device to find the delta (next image is how it was supposed to look). I was actually sending 3 extra empty bytes in front of each intended byte... there was a single line in my code where I accidentally converted an Arduino 'byte' type to 'int' which is 4x the size I was having issues for the longest time getting the code to work on the Raspberry Pi even though it was working fine on the Arduino. This took an EMBARRASSINGLY long time to realize and I finally had to break out the oscilloscope and decode the data being sent from each device to find the delta (next image is how it was supposed to look). I was actually sending 3 extra empty bytes in front of each intended byte... there was a single line in my code where I accidentally converted an Arduino 'byte' type to 'int' which is 4x the size \u{1F926}\u200D\u2642\uFE0F. "),t(),a(22,"img",5),e(23,"p"),i(24," Here is an example of drawing text and individual pixels [TURN SOUND ON]. I wrote a simple library for drawing text, lines, points, and raw black/white bitmaps to the screen. "),t(),e(25,"video",6),a(26,"source",7),t(),e(27,"p"),i(28," This next video came from experimenting with finding the max refresh rate of the displays, which happens to be about 10 fps [TURN SOUND ON]. "),t(),e(29,"video",6),a(30,"source",8),t(),e(31,"p"),i(32," Currently this project is on hiatus but will be resumed (really!). I'm very close to finishing the depth camera integration, currently there is a but in which the output bitmaps are written offset, like header packets from the depth camera are being interpreted as sensor data. I'm working through the issue and it will get fixed. "),t()()())},dependencies:[c,h,l,d,m,p],styles:["mat-card[_ngcontent-%COMP%]{margin:20px 5%}mat-card-title[_ngcontent-%COMP%]{margin-top:20px!important}h1[_ngcontent-%COMP%]{margin-top:0}img[_ngcontent-%COMP%]{min-height:130px;width:100%}video[_ngcontent-%COMP%]{min-height:130px;width:100%}.divider[_ngcontent-%COMP%]{border-top:1px solid white;margin-bottom:1em}.youtube-player[_ngcontent-%COMP%]{aspect-ratio:16/9;display:block;margin:1em 0;width:100%}"]})}}return n})();export{k as FlipDotDisplayPage};
